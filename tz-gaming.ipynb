{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "registered-disease",
   "metadata": {},
   "source": [
    "# TZ Gaming: Optimal Targeting of Mobile Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrsm as rsm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "\n",
    "# increase plot resolution\n",
    "# mpl.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the working directory used, should be location of this notebook\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "tz_gaming = pd.read_pickle(\"data/tz_gaming.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-folks",
   "metadata": {},
   "source": [
    "## Part I: Logistic regression\n",
    "a. Estimate a logistic regression model with the following variables `time_fct app mobile_os impua clua ctrua` as the explanatory and `click_yes` as the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_gaming[\"click_yes\"] = (tz_gaming[\"click\"] == \"yes\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression via statsmodel (using the formula API)\n",
    "lr_mod = smf.glm(\n",
    "    formula=\"click_yes ~ time_fct + app + mobile_os + impua + clua + ctrua\",\n",
    "    family=Binomial(link=logit()),\n",
    "    data=\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-housing",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "###  b. Summarize and interpret the logistic regression results\n",
    "\n",
    "Which of these explanatory variables are statistically significant? Which variables seem to be most “important”? Make sure your model evaluation includes (1) an interpretation of the odds-ratios estimated for the explanatory variables mobile_os, impua, clua, and ctrua and (2) an evaluation of the model as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss and add any code need to calculate additional statistics you may need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-batch",
   "metadata": {},
   "source": [
    "c. Estimate a logistic regression model with `click_yes` as the response variable and `imppat`, `clpat`, and\n",
    "`ctrpat` as the only explanatory variable. Make sure to standardize the explanatory variables before estimation (see example code below). What is the interpretation of the standardized odds-ratios for the explanatory variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all numeric variables in the data\n",
    "is_num = [\n",
    "    \"time\"\n",
    "    \"impup\",\n",
    "    \"clup\",\n",
    "    \"ctrup\",\n",
    "    \"impua\",\n",
    "    \"clua\",\n",
    "    \"ctrua\",\n",
    "    \"imput\",\n",
    "    \"clut\",\n",
    "    \"ctrut\",\n",
    "    \"imppat\",\n",
    "    \"clpat\",\n",
    "    \"ctrpat\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale by (x - mean(x)) / (2 * sd(x))\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sf = scaler.fit(tz_gaming.query(\"training == 'train'\")[is_num])\n",
    "sf.scale_ = sf.scale_ * 2\n",
    "tz_std = tz_gaming.copy()\n",
    "tz_std[is_num] = sf.transform(tz_std[is_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code to estimate the modeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disucss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-plane",
   "metadata": {},
   "source": [
    "d. Some of the variables in the dataset are highly correlated with each other. In particular, imppat\n",
    "and clpat have a positive correlation of 0.97. Discuss the implications of this (very) high level of\n",
    "collinearity and also different approaches to deal with it. What are the implications for the model and\n",
    "the interpretation of the estimated (standardized) coefficients? As part of your answer, discuss the\n",
    "change in the estimated (standardized) odd-ratio for imppat when you remove clpat from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here\n",
    "# hint: review the help for the `vif` function in the pyrsm function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-reconstruction",
   "metadata": {},
   "source": [
    "e. Estimate another logistic regression model with `click_yes` as the response variable and `time_fct`,\n",
    "`app`, `imppat`, `clpat`, and `ctrpat` as the explanatory variable. Why are the odds ratios for `imppat`,\n",
    "`clpat`, and `ctrpat` different in the two models? Please be specific and investigate beyond simply\n",
    "stating the statistical problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-probe",
   "metadata": {},
   "source": [
    "## Part II: Decile Analysis of Logistic Regression Results\n",
    "### a. Create deciles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-humidity",
   "metadata": {},
   "source": [
    "a. Assign each impression to a decile based on the predicted probability of click through. Create a new\n",
    "variable dec_logit that captures this information. Note: The first decile should have the highest\n",
    "average click-through rate. If not, make sure to “reverse” the decile numbers (i.e., 10 becomes 1, 9\n",
    "becomes 2, etc.). Please use the xtile function from the pyrsm package to create the deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-teach",
   "metadata": {},
   "source": [
    "b. Create a bar chart of click-through rates per decile (i.e., use dec_logit as the x-variable and ‘click_yes\n",
    "as the y-variable). Note that the “click through rate” is not the same as the “predicted probability of\n",
    "click.” The click through rate captures the proportion of impressions in a given group (e.g., in a decile)\n",
    "that actually resulted in a click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-sunrise",
   "metadata": {},
   "source": [
    "c. Report the number of impressions, the number of clicks, and the click-through rate for the TZ ad per\n",
    "decile and save this information to a dataframe. Use the name dec_df_logit for the new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-fraud",
   "metadata": {},
   "source": [
    "## Part III: Lift and Gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-layer",
   "metadata": {},
   "source": [
    "a. Use the dataframe you created in II.c above to generate a table with lift and cumulative lift numbers\n",
    "for each decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-commercial",
   "metadata": {},
   "source": [
    "b. Use seaborn or matplotlib to create a chart showing the cumulative lift per decile. Put cumulative\n",
    "lift on the Y-axis and cumulative proportion of impressions on the X-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-bonus",
   "metadata": {},
   "source": [
    "c. Use the data frame you created in II.c above to generate a table with gains and cumulative gains\n",
    "numbers for each decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-finance",
   "metadata": {},
   "source": [
    "d. Use seaborn or matplotlib to create a chart showing the cumulative gains per decile along with a\n",
    "(diagonal) reference line to represent the \"no model\" scenario. Put cumulative gains on the Y-axis and\n",
    "cumulative proportion of impressions on the X-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-nylon",
   "metadata": {},
   "source": [
    "# Part IV: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-manufacturer",
   "metadata": {},
   "source": [
    "a. Create a “confusion matrix” based on the predictions from the logistic regression model you estimated\n",
    "above for I.a. Again, use only data from the test set here (i.e., “training == ‘test’ ”). Use the\n",
    "financial assumptions mentioned above, and repeated in section V below, to determine an appropriate\n",
    "cut-off (i.e., break-even). Calculate “accuracy” based on the confusion matrix you created (see http:\n",
    "//lab.rady.ucsd.edu/sawtooth/RBusinessAnalytics/logit_models.html for an example using R)\n",
    "Note: Do not use any specialized packages to construct the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-fluid",
   "metadata": {},
   "source": [
    "b. Calculate a confusion matrix based on predictions from a logistic regression with click_yes as the\n",
    "response variable and rnd as the only explanatory variable. As before, the model should be estimated\n",
    "on training sample (i.e., “training == ‘train’ ”). Generate predictions for all rows in the data and create\n",
    "the confusion matrix based only on the test set (i.e., “training == ‘test’ ”). Calculate “accuracy” based\n",
    "on the confusion matrix you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-pacific",
   "metadata": {},
   "source": [
    "c. Discuss the similarities and differences between the two confusion matrices. Which model is best, based\n",
    "on the confusion matrix? Provide support for your conclusions.\n",
    "4"
   ]
  },
  {
   "source": [
    "# insert your answer here"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "billion-obligation",
   "metadata": {},
   "source": [
    "d. Recalculate the confusion matrices from IV.a and IV.b using 0.5 as the cutoff. Based on these new\n",
    "matrices, discuss again the similarities and differences. Which model is best based on the confusion\n",
    "matrix? Provide support for your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-diversity",
   "metadata": {},
   "source": [
    "## Part V: Profitability Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-diving",
   "metadata": {},
   "source": [
    "a. Create a new variable target_logit that is True if the predicted click-through probability is greater\n",
    "than the break-even response rate you calculated in IV.a and FALSE otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-manner",
   "metadata": {},
   "source": [
    "b. For the test set (i.e, “training == ‘test’ ”), what is the expected profit (in dollars) and the expected\n",
    "return on marketing expenditures (ROME) if TZ used (1) no targeting, (2) purchased the data from\n",
    "Vneta and used the logistic regression from I.a for targeting, or (3) used Vneta’s data science consulting\n",
    "services? You can use the click_vneta variable to create a target_vneta variable and calculate the\n",
    "expected profit and the expected return on marketing expenditures\n",
    "\n",
    "Note: To estimate the performance implications of “no targeting” approach use the predictions\n",
    "from the model you estimated in IV.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-cabinet",
   "metadata": {},
   "source": [
    "c. Predict the profit and ROME implications for each of the 3 options if TZ purchases 20-million impression\n",
    "for the upcoming ad campaign? Use the results from (b) above to project the performance\n",
    "implications\n",
    "\n",
    "Note: The currently available data (+ the click_vneta prediction) are free as part of the partnership\n",
    "between Vneta and TZ-gaming. You should assume, however, that the total cost of the\n",
    "data would be (50K) and that the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-budget",
   "metadata": {},
   "source": [
    "## Part VI: Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-receiver",
   "metadata": {},
   "source": [
    "a. The calculations in V.a through V.c above assume that the predicted probabilities are estimated\n",
    "without error. Calculate the confidence interval for the predictions from the logistic regression model\n",
    "shown below. Now redo the calculations from V.a through V.c, for this, adjusting for estimation errors.\n",
    "How do your results change?\n",
    "\n",
    "Create a variable `target_logit_lb` that is `True` if the predicted click-through probability is greater than the break-even response rate and `False` otherwise. Add the columns you need from the \"pred\" data frame to your data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mod = smf.glm(\n",
    "    formula=\"click_yes ~ mobile_os + impua + clua + ctrua\",\n",
    "    family=Binomial(link=logit()),\n",
    "    data=,\n",
    ")\n",
    "lr = lr_mod.fit()\n",
    "lr.summary()\n",
    "pred = rsm.predict_ci(lr, , alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-depth",
   "metadata": {},
   "source": [
    "b. You have now estimated 3 different models and also have the predictions from Vneta (see prediction\n",
    "labels below). Compare the models using (1) profit calculations as in V.a through V.c and (2) a gains\n",
    "chart. Discuss which of these 5 models you would recommend to put into production and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your answer here"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}